---
layout: default
title: "Online privacy and transparency – between desire and need"
description:  "Online privacy and transparency – between desire and need"
blurb: "This is a reblog from a LinkedIn post written by Blanca Mayayo, DTL Program Manager and Policy Team member"
date:   2016-03-23 11:55:05 +0100
categories: Blog	
type: blog
author: "Blanca Mayayo"
---

<div class="post-container">
<h3> Online privacy and transparency – between desire and need</h3> 


<div class="post-date">
{{ page.date | date_to_string }}
</div>

<div class="blurb">
{{ page.blurb }}. Originally published on Feb. 22, 2016
</div>

<div class="post-body">
<p>
Some weeks ago the Federal Trade Commission made its position clear on consumer privacy during <a href="http://www.mediapost.com/publications/article/267211/ftc-to-ad-tech-industry-more-transparency-user-c.html">AdExchanger’s Industry Preview</a>, actually expressing surprise to the lack of motivation from the ad-tech industry to offer consumers more tools to protect their privacy. As per some recent <a href="https://digitalcontentnext.org/blog/press/digital-content-next-research-indicates-33-of-consumers-likely-to-try-ad-blocking-software-in-next-three-months/">research indicates</a>, the increased usage of ad blockers could be due not only to the deteriorating experience, but to the <b>lack of trust</b> driven by the relentless and obscure forms of tracking that may come with advertising.
  </p>

<p>
This is yet another example illustrating the human dilemma of ignoring certain potentially dangerous situations until they become an imperative need. The desire is transforming into need: <em>need to preserve trust of users and for entire businesses to survive.</em>
 </p>
<br>
<h5>Beyond Privacy</h5>
 <p>
 Indeed one of the main challenges around big data is privacy, but as automated processes in decision-making are everyday more embedded into our lives, the span of possible risks becomes more complex and difficult to tackle. Even governments have already acknowledged that big data technologies can cause <a href="http://www.whitehouse.gov/sites/default/files/docs/big_data_privacy_report_may_1_2014.pdf">“societal harms beyond damages to privacy”.</a>
</p>
<p>
	Algorithms are being used in a huge array of areas in our everyday life, to the extent that they shape what we see or what we are eligible for. Even more concerning than their ubiquity is how invisible their operations are on a daily basis. People have very little insight into what data is fed into these coding structures, or how it affects decision-making. Moreover, negative effects, such as discrimination, can be enhanced by algorithms even in the absence of explicit discriminatory intent.


</p>

<p>	Although data protection limits the undefined and unaccountable use of data, as it is set forth transparency remains not an enforceable right, or at least, requires huge technical investigation to demonstrate and provide evidence. As it is already covered as a principle in EU data protection regulation, transparency and right to fair processing of data should do the way from desire to need in order to achieve sustainability.</p>
<p>
	
Discussion on how this big data algorithmic transparency - <a href="http://blogs.lse.ac.uk/mediapolicyproject/2016/02/10/accountable-algorithms-a-provocation/">at least to the extent that accountability is guaranteed</a> - can be achieved remains ahead and goes well beyond discussion on just privacy-related issues. In any case, it needs to be acknowledged that it will soon be no longer just a desirable way to “improve customer engagement and experience”, but a real need to regain trust from users and making the balance of access, content and privacy the right one for each individual.

</p>


<!-- <div class="row">
	<div class="col-sm-12"> 
		<a href="http://www.dtlconferences.org/"><img class="img-responsive" title="" src="/images/2016-jumbologo.png"> </a>
	</div>
	</div> -->

 <p>
 
</p>
<!-- close post body -->
</div>
</div>
